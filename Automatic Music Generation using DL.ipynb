{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    print('Loading Music File:', file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    midi = converter.parse(file)\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    for part in s2.parts:\n",
    "        if 'Piano' in str(part):\n",
    "            notes_to_parse = part.recurse()\n",
    "            \n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                    \n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                    \n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path='schubert/'\n",
    "\n",
    "files=[i for i in os.listdir(path) if i.endswith('.mid')]\n",
    "notes_array = np.array([read_midi(path+i) for i in files]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
       " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
       "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
       "        1.4700e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "no=[count for _, count in freq.items()]\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "frequency_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequency_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequency_notes:\n",
    "            temp.append(note_)\n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timestamps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timestamps, 1):\n",
    "        input_ = note_[i:i + no_of_timestamps]\n",
    "        output = note_[i + no_of_timestamps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_,number) for number, note_ in enumerate(unique_x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_,number) for number, note_ in enumerate(unique_y))\n",
    "y_seq = np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nagarc1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\nagarc1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 100)           16700     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 167)               42919     \n",
      "=================================================================\n",
      "Total params: 267,939\n",
      "Trainable params: 267,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import * \n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as k\n",
    "\n",
    "k.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32, trainable=True))\n",
    "\n",
    "model.add(Conv1D(64, 3, padding='causal', activation='relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu', dilation_rate=2, padding='causal')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256, 3, activation='relu', dilation_rate=4, padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nagarc1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\nagarc1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 51530 samples, validate on 12883 samples\n",
      "Epoch 1/50\n",
      "51530/51530 [==============================] - 20s 386us/step - loss: 4.3129 - val_loss: 4.0313\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.03131, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "51530/51530 [==============================] - 19s 372us/step - loss: 3.7858 - val_loss: 3.7875\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.03131 to 3.78752, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "51530/51530 [==============================] - 22s 428us/step - loss: 3.6156 - val_loss: 3.7285\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.78752 to 3.72846, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "51530/51530 [==============================] - 22s 428us/step - loss: 3.4887 - val_loss: 3.5899\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.72846 to 3.58995, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "51530/51530 [==============================] - 22s 436us/step - loss: 3.3820 - val_loss: 3.4988\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.58995 to 3.49885, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "51530/51530 [==============================] - 23s 437us/step - loss: 3.3005 - val_loss: 3.4225\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.49885 to 3.42247, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "51530/51530 [==============================] - 22s 435us/step - loss: 3.2267 - val_loss: 3.4013\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.42247 to 3.40130, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "51530/51530 [==============================] - 23s 446us/step - loss: 3.1636 - val_loss: 3.3305\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.40130 to 3.33046, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "51530/51530 [==============================] - 24s 464us/step - loss: 3.1027 - val_loss: 3.2865\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.33046 to 3.28646, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "51530/51530 [==============================] - 22s 431us/step - loss: 3.0476 - val_loss: 3.2532\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.28646 to 3.25321, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "51530/51530 [==============================] - 23s 442us/step - loss: 3.0035 - val_loss: 3.2177\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.25321 to 3.21772, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "51530/51530 [==============================] - 23s 437us/step - loss: 2.9592 - val_loss: 3.1994\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.21772 to 3.19941, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "51530/51530 [==============================] - 23s 447us/step - loss: 2.9153 - val_loss: 3.1792\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.19941 to 3.17919, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "51530/51530 [==============================] - 23s 450us/step - loss: 2.8800 - val_loss: 3.1216\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.17919 to 3.12156, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "51530/51530 [==============================] - 23s 442us/step - loss: 2.8362 - val_loss: 3.0952\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.12156 to 3.09517, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "51530/51530 [==============================] - 23s 453us/step - loss: 2.8104 - val_loss: 3.0800\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.09517 to 3.08004, saving model to best_model.h5\n",
      "Epoch 17/50\n",
      "51530/51530 [==============================] - 23s 446us/step - loss: 2.7788 - val_loss: 3.0469\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.08004 to 3.04693, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "51530/51530 [==============================] - 23s 453us/step - loss: 2.7481 - val_loss: 3.0407\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.04693 to 3.04065, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "51530/51530 [==============================] - 23s 454us/step - loss: 2.7236 - val_loss: 3.0137\n",
      "\n",
      "Epoch 00019: val_loss improved from 3.04065 to 3.01366, saving model to best_model.h5\n",
      "Epoch 20/50\n",
      "51530/51530 [==============================] - 27s 525us/step - loss: 2.6978 - val_loss: 3.0088\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.01366 to 3.00879, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "51530/51530 [==============================] - 26s 503us/step - loss: 2.6707 - val_loss: 3.0074\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.00879 to 3.00736, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "51530/51530 [==============================] - 26s 502us/step - loss: 2.6546 - val_loss: 2.9782\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.00736 to 2.97818, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "51530/51530 [==============================] - 25s 492us/step - loss: 2.6282 - val_loss: 2.9455\n",
      "\n",
      "Epoch 00023: val_loss improved from 2.97818 to 2.94546, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "51530/51530 [==============================] - 26s 495us/step - loss: 2.6139 - val_loss: 2.9363\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.94546 to 2.93627, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "51530/51530 [==============================] - 25s 484us/step - loss: 2.5897 - val_loss: 2.9380\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.93627\n",
      "Epoch 26/50\n",
      "51530/51530 [==============================] - 25s 490us/step - loss: 2.5742 - val_loss: 2.9034\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.93627 to 2.90336, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "51530/51530 [==============================] - 26s 503us/step - loss: 2.5559 - val_loss: 2.9175\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.90336\n",
      "Epoch 28/50\n",
      "51530/51530 [==============================] - 27s 525us/step - loss: 2.5401 - val_loss: 2.9025\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.90336 to 2.90249, saving model to best_model.h5\n",
      "Epoch 29/50\n",
      "51530/51530 [==============================] - 26s 502us/step - loss: 2.5248 - val_loss: 2.8859\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.90249 to 2.88588, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "51530/51530 [==============================] - 26s 513us/step - loss: 2.5129 - val_loss: 2.8837\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.88588 to 2.88370, saving model to best_model.h5\n",
      "Epoch 31/50\n",
      "51530/51530 [==============================] - 26s 511us/step - loss: 2.4996 - val_loss: 2.8762\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.88370 to 2.87617, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "51530/51530 [==============================] - 24s 473us/step - loss: 2.4837 - val_loss: 2.8596\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.87617 to 2.85959, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "51530/51530 [==============================] - 23s 452us/step - loss: 2.4766 - val_loss: 2.8618\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.85959\n",
      "Epoch 34/50\n",
      "51530/51530 [==============================] - 23s 453us/step - loss: 2.4651 - val_loss: 2.8630\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.85959\n",
      "Epoch 35/50\n",
      "51530/51530 [==============================] - 24s 467us/step - loss: 2.4456 - val_loss: 2.8454\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.85959 to 2.84536, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "51530/51530 [==============================] - 24s 468us/step - loss: 2.4369 - val_loss: 2.8428\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.84536 to 2.84276, saving model to best_model.h5\n",
      "Epoch 37/50\n",
      "51530/51530 [==============================] - 24s 458us/step - loss: 2.4266 - val_loss: 2.8341\n",
      "\n",
      "Epoch 00037: val_loss improved from 2.84276 to 2.83415, saving model to best_model.h5\n",
      "Epoch 38/50\n",
      "51530/51530 [==============================] - 24s 466us/step - loss: 2.4180 - val_loss: 2.8281\n",
      "\n",
      "Epoch 00038: val_loss improved from 2.83415 to 2.82805, saving model to best_model.h5\n",
      "Epoch 39/50\n",
      "51530/51530 [==============================] - 24s 466us/step - loss: 2.4073 - val_loss: 2.8210\n",
      "\n",
      "Epoch 00039: val_loss improved from 2.82805 to 2.82101, saving model to best_model.h5\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 23s 453us/step - loss: 2.3918 - val_loss: 2.8125\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.82101 to 2.81253, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "51530/51530 [==============================] - 23s 454us/step - loss: 2.3955 - val_loss: 2.8144\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.81253\n",
      "Epoch 42/50\n",
      "51530/51530 [==============================] - 23s 455us/step - loss: 2.3826 - val_loss: 2.8199\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.81253\n",
      "Epoch 43/50\n",
      "51530/51530 [==============================] - 24s 458us/step - loss: 2.3705 - val_loss: 2.8128\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.81253\n",
      "Epoch 44/50\n",
      "51530/51530 [==============================] - 24s 473us/step - loss: 2.3659 - val_loss: 2.8034\n",
      "\n",
      "Epoch 00044: val_loss improved from 2.81253 to 2.80343, saving model to best_model.h5\n",
      "Epoch 45/50\n",
      "51530/51530 [==============================] - 23s 446us/step - loss: 2.3540 - val_loss: 2.7879\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.80343 to 2.78787, saving model to best_model.h5\n",
      "Epoch 46/50\n",
      "51530/51530 [==============================] - 23s 455us/step - loss: 2.3456 - val_loss: 2.7873\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.78787 to 2.78732, saving model to best_model.h5\n",
      "Epoch 47/50\n",
      "51530/51530 [==============================] - 23s 453us/step - loss: 2.3474 - val_loss: 2.7761\n",
      "\n",
      "Epoch 00047: val_loss improved from 2.78732 to 2.77615, saving model to best_model.h5\n",
      "Epoch 48/50\n",
      "51530/51530 [==============================] - 23s 444us/step - loss: 2.3375 - val_loss: 2.7771\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.77615\n",
      "Epoch 49/50\n",
      "51530/51530 [==============================] - 23s 452us/step - loss: 2.3227 - val_loss: 2.7877\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.77615\n",
      "Epoch 50/50\n",
      "51530/51530 [==============================] - 23s 446us/step - loss: 2.3247 - val_loss: 2.7783\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.77615\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50,validation_data=(np.array(x_val),\n",
    "                np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 17, 17, 133, 17, 17, 17, 17, 17, 17]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1,no_of_timestamps)\n",
    "    \n",
    "    prob = model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis=0)\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    random_music = np.insert(random_music[0], len(random_music[0]), y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
